{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPhcT+QT37sPkUmJw3oP9ZB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#Step 1: Set Up Your Project Folder"],"metadata":{"id":"4v_u5R339QeE"}},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gBkLMxhVz71d","executionInfo":{"status":"ok","timestamp":1757146492077,"user_tz":-330,"elapsed":89,"user":{"displayName":"Abhishek Raj","userId":"10514513980089682227"}},"outputId":"7ea22c6d-e00e-45ee-a673-9376638de8f5"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/Utensil_Classifier_V2/Utensil_Classifier_V2/Utensil_Classifier_V2/Utensil_Classifier_V2/Utensil_Classifier_V2\n","✅ Project folder 'Utensil_Classifier_V2' and all sub-folders created successfully.\n","\n","Your project structure now looks like this:\n",".:\n","data  models  notebooks\n","\n","./data:\n","fork  others  spoon\n","\n","./data/fork:\n","\n","./data/others:\n","\n","./data/spoon:\n","\n","./models:\n","\n","./notebooks:\n"]}],"source":["# --- STEP 1: CREATE PROJECT DIRECTORY STRUCTURE ---\n","\n","# Define the name of our main project folder\n","PROJECT_NAME = \"Utensil_Classifier_V2\"\n","\n","# Create all the necessary folders in one go\n","import os\n","os.makedirs(f\"{PROJECT_NAME}/data/spoon\", exist_ok=True)\n","os.makedirs(f\"{PROJECT_NAME}/data/fork\", exist_ok=True)\n","os.makedirs(f\"{PROJECT_NAME}/data/others\", exist_ok=True) # For \"none of them\"\n","os.makedirs(f\"{PROJECT_NAME}/models\", exist_ok=True)\n","os.makedirs(f\"{PROJECT_NAME}/notebooks\", exist_ok=True)\n","\n","# Move into our main project folder to keep things organized\n","%cd {PROJECT_NAME}\n","\n","print(f\"✅ Project folder '{PROJECT_NAME}' and all sub-folders created successfully.\")\n","print(\"\\nYour project structure now looks like this:\")\n","# The '!ls -R' command lists all files and folders recursively\n","!ls -R"]},{"cell_type":"markdown","source":["#Step 2: Data Collection & Upload"],"metadata":{"id":"RxIXvAct81Gd"}},{"cell_type":"markdown","source":["#Step 3: Create and Run the Training Notebook"],"metadata":{"id":"U-e2C6Z-84Zh"}},{"cell_type":"code","source":["# --- STEP 3 (REVISED): CREATE AND POPULATE THE TRAINING NOTEBOOK ---\n","\n","# This command writes the entire Python script into the notebook file.\n","# The 'py' at the end of the first line tells Colab to treat this as Python code.\n","%%writefile notebooks/train_multiclass_model.ipynb\n","#\n","# ==============================================================================\n","# SCRIPT FOR: train_multiclass_model.ipynb\n","# GOAL: Train a model to classify images into three categories:\n","#       spoon, fork, and others.\n","# ==============================================================================\n","\n","# --- 1. IMPORT LIBRARIES ---\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n","from tensorflow.keras.applications import MobileNetV2\n","from tensorflow.keras.optimizers import Adam\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","\n","print(\"TensorFlow Version:\", tf.__version__)\n","\n","# --- 2. DEFINE PROJECT PARAMETERS ---\n","IMG_HEIGHT, IMG_WIDTH = 224, 224\n","BATCH_SIZE = 8\n","DATA_DIR = '../data/'\n","MODEL_SAVE_PATH = '../models/multiclass_detector.h5'\n","\n","# --- 3. PREPARE THE DATA ---\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=25,\n","    horizontal_flip=True,\n","    validation_split=0.2\n",")\n","validation_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    DATA_DIR,\n","    target_size=(IMG_HEIGHT, IMG_WIDTH),\n","    batch_size=BATCH_SIZE,\n","    class_mode='categorical',\n","    subset='training'\n",")\n","validation_generator = validation_datagen.flow_from_directory(\n","    DATA_DIR,\n","    target_size=(IMG_HEIGHT, IMG_WIDTH),\n","    batch_size=BATCH_SIZE,\n","    class_mode='categorical',\n","    subset='validation'\n",")\n","\n","print(f\"Class indices found: {train_generator.class_indices}\")\n","num_classes = len(train_generator.class_indices)\n","\n","# --- 4. BUILD THE MODEL ---\n","base_model = MobileNetV2(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), include_top=False, weights='imagenet')\n","base_model.trainable = False\n","model = Sequential([\n","    base_model,\n","    GlobalAveragePooling2D(),\n","    Dropout(0.5),\n","    Dense(num_classes, activation='softmax')\n","])\n","\n","# --- 5. COMPILE THE MODEL ---\n","model.compile(\n","    optimizer=Adam(learning_rate=0.001),\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","model.summary()\n","\n","# --- 6. TRAIN THE MODEL ---\n","print(\"\\n--- Starting Model Training ---\")\n","history = model.fit(\n","    train_generator,\n","    epochs=30,\n","    validation_data=validation_generator\n",")\n","print(\"--- Model Training Complete ---\")\n","\n","# --- 7. SAVE THE FINAL TRAINED MODEL ---\n","model.save(MODEL_SAVE_PATH)\n","print(f\"\\n✅ Model successfully saved to: {MODEL_SAVE_PATH}\")\n","\n","# --- 8. VISUALIZE TRAINING RESULTS ---\n","acc = history.history['accuracy']\n","val_acc = history.history['validation_accuracy']\n","loss = history.history['loss']\n","val_loss = history.history['validation_loss']\n","epochs_range = range(len(acc))\n","\n","plt.figure(figsize=(14, 6))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy', marker='o')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy', marker='o')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","plt.grid(True)\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss', marker='o')\n","plt.plot(epochs_range, val_loss, label='Validation Loss', marker='o')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"Zrq5NUI7Bb96","executionInfo":{"status":"ok","timestamp":1757146492112,"user_tz":-330,"elapsed":37,"user":{"displayName":"Abhishek Raj","userId":"10514513980089682227"}},"outputId":"dc5c824d-2c41-40d6-a04e-b1e2154fc649","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing notebooks/train_multiclass_model.ipynb\n"]}]},{"cell_type":"markdown","source":["#optimized  note book"],"metadata":{"id":"PBnPJzxaFaNZ"}},{"cell_type":"code","source":["# --- CREATE THE NEW, ADVANCED TRAINING NOTEBOOK ---\n","\n","%%writefile notebooks/train_optimized_model.ipynb\n","#\n","# ==============================================================================\n","# NOTEBOOK: train_optimized_model.ipynb\n","# PURPOSE:  To train a highly accurate model using advanced techniques like\n","#           Learning Rate Scheduling and Fine-Tuning.\n","# ==============================================================================\n","\n","# --- 1. IMPORT LIBRARIES ---\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n","from tensorflow.keras.applications import MobileNetV2\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ReduceLROnPlateau # For optimization\n","import matplotlib.pyplot as plt\n","import os\n","\n","print(f\"TensorFlow Version: {tf.__version__}\")\n","print(f\"Timestamp (Bareilly, India): {os.popen('TZ=\\\"Asia/Kolkata\\\" date').read().strip()}\")\n","\n","\n","# --- 2. DEFINE PROJECT PARAMETERS ---\n","IMG_HEIGHT, IMG_WIDTH = 224, 224\n","BATCH_SIZE = 8\n","DATA_DIR = '../data/'\n","# We will save two models: the initial one, and the final fine-tuned one.\n","INITIAL_MODEL_SAVE_PATH = '../models/multiclass_detector_initial.h5'\n","FINAL_MODEL_SAVE_PATH = '../models/multiclass_detector_fine_tuned.h5' # This is our best model\n","\n","\n","# --- 3. PREPARE DATA GENERATORS ---\n","# We add more augmentation like brightness adjustments for better generalization.\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=30,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    brightness_range=[0.8, 1.2],\n","    validation_split=0.2\n",")\n","validation_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    DATA_DIR,\n","    target_size=(IMG_HEIGHT, IMG_WIDTH),\n","    batch_size=BATCH_SIZE,\n","    class_mode='categorical',\n","    subset='training'\n",")\n","validation_generator = validation_datagen.flow_from_directory(\n","    DATA_DIR,\n","    target_size=(IMG_HEIGHT, IMG_WIDTH),\n","    batch_size=BATCH_SIZE,\n","    class_mode='categorical',\n","    subset='validation'\n",")\n","\n","print(f\"Class indices found: {train_generator.class_indices}\")\n","num_classes = len(train_generator.class_indices)\n","\n","\n","# --- 4. PHASE 1: INITIAL TRAINING (WITH FROZEN BASE) ---\n","base_model = MobileNetV2(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), include_top=False, weights='imagenet')\n","base_model.trainable = False # Keep the pre-trained layers frozen\n","\n","model = Sequential([\n","    base_model,\n","    GlobalAveragePooling2D(),\n","    Dropout(0.5),\n","    Dense(num_classes, activation='softmax')\n","])\n","\n","model.compile(\n","    optimizer=Adam(learning_rate=0.001),\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","# Define the Learning Rate Scheduler to reduce LR when validation loss plateaus\n","lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, verbose=1, min_lr=1e-6)\n","\n","print(\"\\n--- Starting INITIAL Training Phase (20 Epochs) ---\")\n","history = model.fit(\n","    train_generator,\n","    epochs=20,\n","    validation_data=validation_generator,\n","    callbacks=[lr_scheduler]\n",")\n","model.save(INITIAL_MODEL_SAVE_PATH)\n","print(f\"Initial model saved to {INITIAL_MODEL_SAVE_PATH}\")\n","\n","\n","# --- 5. PHASE 2: FINE-TUNING ---\n","print(\"\\n--- Starting FINE-TUNING Phase (15 More Epochs) ---\")\n","\n","# Unfreeze the top layers of the base model to allow them to be trained\n","base_model.trainable = True\n","# We'll fine-tune from the 100th layer onwards. Early layers detect basic shapes and should remain frozen.\n","fine_tune_at = 100\n","for layer in base_model.layers[:fine_tune_at]:\n","    layer.trainable = False\n","\n","# Re-compile the model with a very low learning rate. This is CRITICAL for fine-tuning.\n","model.compile(\n","    optimizer=Adam(learning_rate=1e-5), # 0.00001\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","model.summary() # Print the model summary to see trainable parameters\n","\n","# Continue training the model to fine-tune the unfrozen layers\n","fine_tune_epochs = 15\n","total_epochs = 20 + fine_tune_epochs\n","\n","history_fine_tune = model.fit(\n","    train_generator,\n","    epochs=total_epochs,\n","    initial_epoch=history.epoch[-1], # Start from where the last training phase ended\n","    validation_data=validation_generator,\n","    callbacks=[lr_scheduler]\n",")\n","\n","\n","# --- 6. SAVE THE FINAL, OPTIMIZED MODEL ---\n","model.save(FINAL_MODEL_SAVE_PATH)\n","print(f\"\\n✅ Final optimized model saved to: {FINAL_MODEL_SAVE_PATH}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fjgk9CI1EHhJ","executionInfo":{"status":"ok","timestamp":1757146492284,"user_tz":-330,"elapsed":32,"user":{"displayName":"Abhishek Raj","userId":"10514513980089682227"}},"outputId":"93790fec-a0fc-4190-ce63-7ba56f95bc86"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing notebooks/train_optimized_model.ipynb\n"]}]}]}